{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"“faceswap-GAN_lite_demo.ipynb”的副本","version":"0.3.2","provenance":[{"file_id":"https://github.com/shaoanlu/faceswap-GAN/blob/master/colab_demo/faceswap-GAN_colab_demo.ipynb","timestamp":1563441564191}],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.4"}},"cells":[{"cell_type":"markdown","metadata":{"colab_type":"text","id":"MiOo3478pJg9"},"source":["# Before we start...\n","\n","This colab notebook is a minimum demo for faceswap-GAN v2.2. Since colab allows maximum run time limit of 12 hrs, we will only train a lightweight model in this notebook. **The purpose of this notebook is not to train a model that produces high quality results but a quick overview for how faceswap-GAN works.**\n","\n","The pipeline of faceswap-GAN v2.2 is described below:\n","\n","  1. Upload two videos for training.\n","  2. Apply face extraction (preprocessing) on the two uploaded videos\n","  3. Train a liteweight faceswap-GAN model. (This will take 10 ~ 12 hrs)\n","  4. Apply video conversion to the uploaded videos."]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"Qf8Wvh5Wrm3V"},"source":["# Step 1: Set runtime type to Python 3/GPU\n","Set the colab notebook to GPU instance through: **runtime -> change runtime type -> Python3 and GPU**\n","\n","The following cells will show the system information of the current instance. Run the cells and check if it uses python >= 3.6 and has a GPU device."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"1zQhhPfKrmQl","outputId":"f7081fa0-5f98-4064-d8b1-fc846d16a71c","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1563441605658,"user_tz":-480,"elapsed":1370,"user":{"displayName":"申恒恒","photoUrl":"https://lh5.googleusercontent.com/-rXn3NCb40hc/AAAAAAAAAAI/AAAAAAAADHs/looj2vH7Tck/s64/photo.jpg","userId":"02723399992930938550"}}},"source":["import platform\n","print(platform.python_version())"],"execution_count":1,"outputs":[{"output_type":"stream","text":["3.6.8\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"1f96C1TApC00","outputId":"1f3a97e3-7776-431a-c863-d38aebea0fe1","colab":{"base_uri":"https://localhost:8080/","height":470},"executionInfo":{"status":"ok","timestamp":1563441624245,"user_tz":-480,"elapsed":4052,"user":{"displayName":"申恒恒","photoUrl":"https://lh5.googleusercontent.com/-rXn3NCb40hc/AAAAAAAAAAI/AAAAAAAADHs/looj2vH7Tck/s64/photo.jpg","userId":"02723399992930938550"}}},"source":["from tensorflow.python.client import device_lib\n","device_lib.list_local_devices()"],"execution_count":2,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[name: \"/device:CPU:0\"\n"," device_type: \"CPU\"\n"," memory_limit: 268435456\n"," locality {\n"," }\n"," incarnation: 4451811606304826068, name: \"/device:XLA_CPU:0\"\n"," device_type: \"XLA_CPU\"\n"," memory_limit: 17179869184\n"," locality {\n"," }\n"," incarnation: 4465572021695700981\n"," physical_device_desc: \"device: XLA_CPU device\", name: \"/device:XLA_GPU:0\"\n"," device_type: \"XLA_GPU\"\n"," memory_limit: 17179869184\n"," locality {\n"," }\n"," incarnation: 17011879061166694691\n"," physical_device_desc: \"device: XLA_GPU device\", name: \"/device:GPU:0\"\n"," device_type: \"GPU\"\n"," memory_limit: 11326753997\n"," locality {\n","   bus_id: 1\n","   links {\n","   }\n"," }\n"," incarnation: 12568679376605034968\n"," physical_device_desc: \"device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7\"]"]},"metadata":{"tags":[]},"execution_count":2}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"XOsTN_gjzonZ"},"source":["# Step 2: Git clone faceswap-GAN"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"L4VioT5YpJQB","outputId":"f3208101-f6aa-4043-c3c6-f303d746ecd0","colab":{"base_uri":"https://localhost:8080/","height":134},"executionInfo":{"status":"ok","timestamp":1563441641900,"user_tz":-480,"elapsed":9726,"user":{"displayName":"申恒恒","photoUrl":"https://lh5.googleusercontent.com/-rXn3NCb40hc/AAAAAAAAAAI/AAAAAAAADHs/looj2vH7Tck/s64/photo.jpg","userId":"02723399992930938550"}}},"source":["!git clone https://github.com/shaoanlu/faceswap-GAN.git"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Cloning into 'faceswap-GAN'...\n","remote: Enumerating objects: 20, done.\u001b[K\n","remote: Counting objects: 100% (20/20), done.\u001b[K\n","remote: Compressing objects: 100% (18/18), done.\u001b[K\n","remote: Total 993 (delta 6), reused 6 (delta 2), pack-reused 973\u001b[K\n","Receiving objects: 100% (993/993), 2.22 MiB | 3.94 MiB/s, done.\n","Resolving deltas: 100% (599/599), done.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"g_4C8o3y0DFD","outputId":"c5422d59-ce8c-4dde-ac89-8a8cb69f8af5","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1563441646138,"user_tz":-480,"elapsed":1059,"user":{"displayName":"申恒恒","photoUrl":"https://lh5.googleusercontent.com/-rXn3NCb40hc/AAAAAAAAAAI/AAAAAAAADHs/looj2vH7Tck/s64/photo.jpg","userId":"02723399992930938550"}}},"source":["%cd \"faceswap-GAN\""],"execution_count":4,"outputs":[{"output_type":"stream","text":["/content/faceswap-GAN\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"K0wsds0OslRc"},"source":["# Step 3: Upload training videos\n","\n","The user should upload two videos: **source video** and **target video**. The model will **tranform source face to target face by default.**\n","\n","  - The videos better **contain only one person**.\n","  - There is no limitation on video length but the longer it is, the longer preprocessing time / video conversion time it will take, which may cause excceded run time of 12 hrs. (**Recommended video length: 30 secs ~ 2 mins.**)"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"EQ0HH6VUpJHW","colab":{}},"source":["from google.colab import files"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"thlzp88qpJJk","colab":{"resources":{"http://localhost:8080/nbextensions/google.colab/files.js":{"data":"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","ok":true,"headers":[["content-type","application/javascript"]],"status":200,"status_text":""}},"base_uri":"https://localhost:8080/","height":114},"outputId":"bea54476-2eca-467c-ea37-cd48f4dbb496","executionInfo":{"status":"ok","timestamp":1563442261104,"user_tz":-480,"elapsed":301285,"user":{"displayName":"申恒恒","photoUrl":"https://lh5.googleusercontent.com/-rXn3NCb40hc/AAAAAAAAAAI/AAAAAAAADHs/looj2vH7Tck/s64/photo.jpg","userId":"02723399992930938550"}}},"source":["# Upload source video\n","source_video = files.upload()\n","\n","for fn_source_video, _ in source_video.items():\n","    print(fn_source_video)"],"execution_count":7,"outputs":[{"output_type":"display_data","data":{"text/html":["\n","     <input type=\"file\" id=\"files-513ce8e9-388d-4559-a409-8d8e886e69a9\" name=\"files[]\" multiple disabled />\n","     <output id=\"result-513ce8e9-388d-4559-a409-8d8e886e69a9\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script src=\"/nbextensions/google.colab/files.js\"></script> "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Saving Can More Than One Person Train a Puppy - ask me anything - Dog Training Video [G28T1aDXB0k].mp4 to Can More Than One Person Train a Puppy - ask me anything - Dog Training Video [G28T1aDXB0k].mp4\n","Can More Than One Person Train a Puppy - ask me anything - Dog Training Video [G28T1aDXB0k].mp4\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"YyKu2hcCpJKu","colab":{"resources":{"http://localhost:8080/nbextensions/google.colab/files.js":{"data":"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","ok":true,"headers":[["content-type","application/javascript"]],"status":200,"status_text":""}},"base_uri":"https://localhost:8080/","height":94},"outputId":"52abe545-ce12-441c-96ac-79e866670f0a","executionInfo":{"status":"ok","timestamp":1563442285266,"user_tz":-480,"elapsed":21158,"user":{"displayName":"申恒恒","photoUrl":"https://lh5.googleusercontent.com/-rXn3NCb40hc/AAAAAAAAAAI/AAAAAAAADHs/looj2vH7Tck/s64/photo.jpg","userId":"02723399992930938550"}}},"source":["# Upload target video\n","target_video = files.upload()\n","\n","for fn_target_video, _ in target_video.items():\n","    print(fn_target_video)"],"execution_count":8,"outputs":[{"output_type":"display_data","data":{"text/html":["\n","     <input type=\"file\" id=\"files-d1cca0f9-6deb-4dfe-b122-215ec362b346\" name=\"files[]\" multiple disabled />\n","     <output id=\"result-d1cca0f9-6deb-4dfe-b122-215ec362b346\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script src=\"/nbextensions/google.colab/files.js\"></script> "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Saving 2017年新春祝福 [YCZirXm63HI].mp4 to 2017年新春祝福 [YCZirXm63HI].mp4\n","2017年新春祝福 [YCZirXm63HI].mp4\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"96jboaxSYIy5","colab_type":"text"},"source":["# Step 4: Set maximum training iterations\n","Default 25000 iters require ~ 10hrs of training.\n","\n","Iterations >= 27k may exceed run time limit; Iterations < 18k may yield poorly-trained model."]},{"cell_type":"code","metadata":{"id":"JAm2CxhrYIy6","colab_type":"code","colab":{}},"source":["global TOTAL_ITERS\n","TOTAL_ITERS = 34000"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"PS25Uu9kxDwo"},"source":["# Step 5: Everything is ready.\n","\n","**Press Ctrl + F10 (or runtime -> run after)** to start the remaining process and leave this page alone. It will take 10 ~ 12 hours to finish training. The result video can be downloaded by running the last cell: \n","  ```python\n","  files.download(\"OUTPUT_VIDEO.mp4\")\n","  # Some browsers do not support this line (e.g., Opera does not pop up a save dialog). Please use Firefox or Chrome.\n","  ```\n","Notice that **this page should not be closed or refreshed while running**."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"BY3qysVq0p2P","colab":{}},"source":["%%capture\n","!pip install moviepy\n","!pip install keras_vggface\n","import imageio\n","imageio.plugins.ffmpeg.download()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"ym0EsJk9pJRw","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"cd71ea34-f11d-4ff4-f71c-f084af61518b","executionInfo":{"status":"ok","timestamp":1563442341009,"user_tz":-480,"elapsed":2100,"user":{"displayName":"申恒恒","photoUrl":"https://lh5.googleusercontent.com/-rXn3NCb40hc/AAAAAAAAAAI/AAAAAAAADHs/looj2vH7Tck/s64/photo.jpg","userId":"02723399992930938550"}}},"source":["import keras.backend as K\n","from detector.face_detector import MTCNNFaceDetector\n","import glob\n","\n","from preprocess import preprocess_video"],"execution_count":11,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"otuzS3Di0gvz","colab":{"base_uri":"https://localhost:8080/","height":390},"outputId":"b58e2259-74c7-458a-f78c-f424fc37358d","executionInfo":{"status":"ok","timestamp":1563442346626,"user_tz":-480,"elapsed":4293,"user":{"displayName":"申恒恒","photoUrl":"https://lh5.googleusercontent.com/-rXn3NCb40hc/AAAAAAAAAAI/AAAAAAAADHs/looj2vH7Tck/s64/photo.jpg","userId":"02723399992930938550"}}},"source":["fd = MTCNNFaceDetector(sess=K.get_session(), model_path=\"./mtcnn_weights/\")"],"execution_count":12,"outputs":[{"output_type":"stream","text":["WARNING: Logging before flag parsing goes to stderr.\n","W0718 09:32:22.936649 139787969185664 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n","\n","W0718 09:32:22.939661 139787969185664 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n","\n","W0718 09:32:22.941212 139787969185664 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:186: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n","\n","W0718 09:32:22.956259 139787969185664 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n","\n","W0718 09:32:22.959331 139787969185664 deprecation_wrapper.py:119] From /content/faceswap-GAN/detector/face_detector.py:25: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n","\n","W0718 09:32:22.970784 139787969185664 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Call initializer instance with the dtype argument instead of passing it to the constructor\n","W0718 09:32:23.029172 139787969185664 deprecation_wrapper.py:119] From /content/faceswap-GAN/mtcnn_detect_face.py:179: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n","\n","W0718 09:32:23.124478 139787969185664 deprecation.py:323] From /content/faceswap-GAN/mtcnn_detect_face.py:215: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Deprecated in favor of operator or tf.math.divide.\n","W0718 09:32:25.083893 139787969185664 deprecation_wrapper.py:119] From /content/faceswap-GAN/mtcnn_detect_face.py:199: The name tf.nn.xw_plus_b is deprecated. Please use tf.compat.v1.nn.xw_plus_b instead.\n","\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Kt5FVEt11B2K","colab":{}},"source":["!mkdir -p faceA/rgb\n","!mkdir -p faceA/binary_mask\n","!mkdir -p faceB/rgb\n","!mkdir -p faceB/binary_mask"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"dO11aRsZ0gyK","colab":{"base_uri":"https://localhost:8080/","height":322},"outputId":"7db336d9-5255-448c-e6fd-086eab962e81","executionInfo":{"status":"ok","timestamp":1563442598652,"user_tz":-480,"elapsed":233954,"user":{"displayName":"申恒恒","photoUrl":"https://lh5.googleusercontent.com/-rXn3NCb40hc/AAAAAAAAAAI/AAAAAAAADHs/looj2vH7Tck/s64/photo.jpg","userId":"02723399992930938550"}}},"source":["save_interval = 5 # perform face detection every {save_interval} frames\n","save_path = \"./faceA/\"\n","preprocess_video(fn_source_video, fd, save_interval, save_path)\n","save_path = \"./faceB/\"\n","preprocess_video(fn_target_video, fd, save_interval, save_path)"],"execution_count":14,"outputs":[{"output_type":"stream","text":["100%|█████████▉| 2354/2358 [03:44<00:00, 10.26it/s]W0718 09:36:30.538460 139787969185664 warnings.py:99] /usr/local/lib/python3.6/dist-packages/moviepy/video/io/ffmpeg_reader.py:130: UserWarning: Warning: in file Can More Than One Person Train a Puppy - ask me anything - Dog Training Video [G28T1aDXB0k].mp4, 6220800 bytes wanted but 0 bytes read,at frame 2355/2358, at time 78.58/78.65 sec. Using the last valid frame instead.\n","  UserWarning)\n","\n","W0718 09:36:30.540033 139787969185664 warnings.py:99] /usr/local/lib/python3.6/dist-packages/moviepy/video/io/ffmpeg_reader.py:130: UserWarning: Warning: in file Can More Than One Person Train a Puppy - ask me anything - Dog Training Video [G28T1aDXB0k].mp4, 6220800 bytes wanted but 0 bytes read,at frame 2356/2358, at time 78.61/78.65 sec. Using the last valid frame instead.\n","  UserWarning)\n","\n","W0718 09:36:30.541258 139787969185664 warnings.py:99] /usr/local/lib/python3.6/dist-packages/moviepy/video/io/ffmpeg_reader.py:130: UserWarning: Warning: in file Can More Than One Person Train a Puppy - ask me anything - Dog Training Video [G28T1aDXB0k].mp4, 6220800 bytes wanted but 0 bytes read,at frame 2357/2358, at time 78.65/78.65 sec. Using the last valid frame instead.\n","  UserWarning)\n","\n","100%|██████████| 2358/2358 [03:44<00:00, 10.48it/s]\n"," 98%|█████████▊| 234/240 [00:07<00:00, 35.19it/s]W0718 09:36:38.077986 139787969185664 warnings.py:99] /usr/local/lib/python3.6/dist-packages/moviepy/video/io/ffmpeg_reader.py:130: UserWarning: Warning: in file 2017年新春祝福 [YCZirXm63HI].mp4, 876960 bytes wanted but 0 bytes read,at frame 238/240, at time 7.93/7.99 sec. Using the last valid frame instead.\n","  UserWarning)\n","\n","100%|█████████▉| 239/240 [00:07<00:00, 35.90it/s]W0718 09:36:38.200910 139787969185664 warnings.py:99] /usr/local/lib/python3.6/dist-packages/moviepy/video/io/ffmpeg_reader.py:130: UserWarning: Warning: in file 2017年新春祝福 [YCZirXm63HI].mp4, 876960 bytes wanted but 0 bytes read,at frame 239/240, at time 7.97/7.99 sec. Using the last valid frame instead.\n","  UserWarning)\n","\n","100%|██████████| 240/240 [00:07<00:00, 32.43it/s]\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"qIb9TSMz0g0g","colab":{"base_uri":"https://localhost:8080/","height":50},"outputId":"12886157-c2cc-461b-f778-c00c740c28f4","executionInfo":{"status":"ok","timestamp":1563442705172,"user_tz":-480,"elapsed":1679,"user":{"displayName":"申恒恒","photoUrl":"https://lh5.googleusercontent.com/-rXn3NCb40hc/AAAAAAAAAAI/AAAAAAAADHs/looj2vH7Tck/s64/photo.jpg","userId":"02723399992930938550"}}},"source":["print(str(len(glob.glob(\"faceA/rgb/*.*\"))) + \" face(s) extracted from source video: \" + fn_source_video + \".\")\n","print(str(len(glob.glob(\"faceB/rgb/*.*\"))) + \" face(s) extracted from target video: \" + fn_target_video + \".\")"],"execution_count":15,"outputs":[{"output_type":"stream","text":["471 face(s) extracted from source video: Can More Than One Person Train a Puppy - ask me anything - Dog Training Video [G28T1aDXB0k].mp4.\n","48 face(s) extracted from target video: 2017年新春祝福 [YCZirXm63HI].mp4.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"O9L5UW8U3AaQ"},"source":["## The following cells are from [FaceSwap_GAN_v2.2_train_test.ipynb](https://github.com/shaoanlu/faceswap-GAN/blob/master/FaceSwap_GAN_v2.2_train_test.ipynb)"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"WtyeXpEc2lDO"},"source":["## Import packages"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"MtENXluJ0g2I","colab":{}},"source":["from keras.layers import *\n","import keras.backend as K\n","import tensorflow as tf"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"HFAokeU12Vff","colab":{}},"source":["import os\n","import cv2\n","import glob\n","import time\n","import numpy as np\n","from pathlib import PurePath, Path\n","from IPython.display import clear_output\n","\n","import matplotlib.pyplot as plt\n","%matplotlib inline"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"EJ1miHVk2ns7"},"source":["## Configuration"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"BjrPsIbZ2ViU","colab":{}},"source":["K.set_learning_phase(1)\n","# Number of CPU cores\n","num_cpus = os.cpu_count()\n","\n","# Input/Output resolution\n","RESOLUTION = 64 # 64x64, 128x128, 256x256\n","assert (RESOLUTION % 64) == 0, \"RESOLUTION should be 64, 128, or 256.\"\n","\n","# Batch size\n","batchSize = 4\n","\n","# Use motion blurs (data augmentation)\n","# set True if training data contains images extracted from videos\n","use_da_motion_blur = False \n","\n","# Use eye-aware training\n","# require images generated from prep_binary_masks.ipynb\n","use_bm_eyes = True\n","\n","# Probability of random color matching (data augmentation)\n","prob_random_color_match = 0.5\n","\n","da_config = {\n","    \"prob_random_color_match\": prob_random_color_match,\n","    \"use_da_motion_blur\": use_da_motion_blur,\n","    \"use_bm_eyes\": use_bm_eyes\n","}\n","\n","# Path to training images\n","img_dirA = './faceA/rgb'\n","img_dirB = './faceB/rgb'\n","img_dirA_bm_eyes = \"./faceA/binary_mask\"\n","img_dirB_bm_eyes = \"./faceB/binary_mask\"\n","\n","# Path to saved model weights\n","models_dir = \"./models\"\n","\n","# Architecture configuration\n","arch_config = {}\n","arch_config['IMAGE_SHAPE'] = (RESOLUTION, RESOLUTION, 3)\n","arch_config['use_self_attn'] = True\n","arch_config['norm'] = \"hybrid\" # instancenorm, batchnorm, layernorm, groupnorm, none\n","arch_config['model_capacity'] = \"lite\" # standard, lite\n","\n","# Loss function weights configuration\n","loss_weights = {}\n","loss_weights['w_D'] = 0.1 # Discriminator\n","loss_weights['w_recon'] = 1. # L1 reconstruction loss\n","loss_weights['w_edge'] = 0.1 # edge loss\n","loss_weights['w_eyes'] = 30. # reconstruction and edge loss on eyes area\n","loss_weights['w_pl'] = (0.01, 0.1, 0.3, 0.1) # perceptual loss (0.003, 0.03, 0.3, 0.3)\n","\n","# Init. loss config.\n","loss_config = {}\n","loss_config[\"gan_training\"] = \"mixup_LSGAN\"\n","loss_config['use_PL'] = False\n","loss_config[\"PL_before_activ\"] = True\n","loss_config['use_mask_hinge_loss'] = False\n","loss_config['m_mask'] = 0.\n","loss_config['lr_factor'] = 1.\n","loss_config['use_cyclic_loss'] = False"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"bSrt2h0K3so3"},"source":["## Build the model"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"5o2dEVW92Vms","colab":{}},"source":["from networks.faceswap_gan_model import FaceswapGANModel\n","from data_loader.data_loader import DataLoader\n","from utils import showG, showG_mask, showG_eyes"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"yiNsc3N_2VhU","colab":{"base_uri":"https://localhost:8080/","height":70},"outputId":"c001f021-cc34-477b-b253-2bfef4338c8e","executionInfo":{"status":"ok","timestamp":1563442747696,"user_tz":-480,"elapsed":4191,"user":{"displayName":"申恒恒","photoUrl":"https://lh5.googleusercontent.com/-rXn3NCb40hc/AAAAAAAAAAI/AAAAAAAADHs/looj2vH7Tck/s64/photo.jpg","userId":"02723399992930938550"}}},"source":["model = FaceswapGANModel(**arch_config)"],"execution_count":20,"outputs":[{"output_type":"stream","text":["W0718 09:39:04.706604 139787969185664 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2018: The name tf.image.resize_nearest_neighbor is deprecated. Please use tf.compat.v1.image.resize_nearest_neighbor instead.\n","\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"qrjRUPgwYIzx","colab_type":"code","colab":{}},"source":["%%capture\n","!wget https://github.com/rcmalli/keras-vggface/releases/download/v2.0/rcmalli_vggface_tf_notop_resnet50.h5"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"qvVr2TqI3jd9","outputId":"2830fd2e-d102-4baf-ded8-7d85176b7fa4","colab":{"base_uri":"https://localhost:8080/","height":238},"executionInfo":{"status":"ok","timestamp":1563442794448,"user_tz":-480,"elapsed":27390,"user":{"displayName":"申恒恒","photoUrl":"https://lh5.googleusercontent.com/-rXn3NCb40hc/AAAAAAAAAAI/AAAAAAAADHs/looj2vH7Tck/s64/photo.jpg","userId":"02723399992930938550"}}},"source":["#from keras_vggface.vggface import VGGFace\n","\n","# VGGFace ResNet50\n","#vggface = VGGFace(include_top=False, model='resnet50', input_shape=(224, 224, 3))'\n","\n","from colab_demo.vggface_models import RESNET50\n","vggface = RESNET50(include_top=False, weights=None, input_shape=(224, 224, 3))\n","vggface.load_weights(\"rcmalli_vggface_tf_notop_resnet50.h5\")\n","\n","#from keras.applications.resnet50 import ResNet50\n","#vggface = ResNet50(include_top=False, input_shape=(224, 224, 3))\n","\n","#vggface.summary()\n","\n","model.build_pl_model(vggface_model=vggface, before_activ=loss_config[\"PL_before_activ\"])\n","model.build_train_functions(loss_weights=loss_weights, **loss_config)"],"execution_count":22,"outputs":[{"output_type":"stream","text":["W0718 09:39:28.393658 139787969185664 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n","\n","W0718 09:39:33.426531 139787969185664 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3980: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n","\n","W0718 09:39:36.571327 139787969185664 deprecation.py:323] From /content/faceswap-GAN/networks/losses.py:44: Beta.__init__ (from tensorflow.python.ops.distributions.beta) is deprecated and will be removed after 2019-01-01.\n","Instructions for updating:\n","The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.\n","W0718 09:39:36.575727 139787969185664 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/distributions/beta.py:208: Distribution.__init__ (from tensorflow.python.ops.distributions.distribution) is deprecated and will be removed after 2019-01-01.\n","Instructions for updating:\n","The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.\n","W0718 09:39:37.981214 139787969185664 deprecation_wrapper.py:119] From /content/faceswap-GAN/networks/losses.py:94: The name tf.image.resize_images is deprecated. Please use tf.image.resize instead.\n","\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"GexJ-i7c3vz2"},"source":["## Start training"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"yoCnWQiR3jgd","colab":{}},"source":["# Create ./models directory\n","Path(f\"models\").mkdir(parents=True, exist_ok=True)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"bjkSygNT3jjB","colab":{"base_uri":"https://localhost:8080/","height":50},"outputId":"049a452e-e511-4453-be4d-2ed6d6332c9f","executionInfo":{"status":"ok","timestamp":1563442801190,"user_tz":-480,"elapsed":615,"user":{"displayName":"申恒恒","photoUrl":"https://lh5.googleusercontent.com/-rXn3NCb40hc/AAAAAAAAAAI/AAAAAAAADHs/looj2vH7Tck/s64/photo.jpg","userId":"02723399992930938550"}}},"source":["# Get filenames\n","train_A = glob.glob(img_dirA+\"/*.*\")\n","train_B = glob.glob(img_dirB+\"/*.*\")\n","\n","train_AnB = train_A + train_B\n","\n","assert len(train_A), \"No image found in \" + str(img_dirA)\n","assert len(train_B), \"No image found in \" + str(img_dirB)\n","print (\"Number of images in folder A: \" + str(len(train_A)))\n","print (\"Number of images in folder B: \" + str(len(train_B)))"],"execution_count":24,"outputs":[{"output_type":"stream","text":["Number of images in folder A: 471\n","Number of images in folder B: 48\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"-KzKahMU3jlX","colab":{}},"source":["def show_loss_config(loss_config):\n","    for config, value in loss_config.items():\n","        print(f\"{config} = {value}\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"j5fwrKth3jqO","colab":{}},"source":["def reset_session(save_path):\n","    global model, vggface\n","    global train_batchA, train_batchB\n","    model.save_weights(path=save_path)\n","    del model\n","    del vggface\n","    del train_batchA\n","    del train_batchB\n","    K.clear_session()\n","    model = FaceswapGANModel(**arch_config)\n","    model.load_weights(path=save_path)\n","    #vggface = VGGFace(include_top=False, model='resnet50', input_shape=(224, 224, 3))\n","    vggface = RESNET50(include_top=False, weights=None, input_shape=(224, 224, 3))\n","    vggface.load_weights(\"rcmalli_vggface_tf_notop_resnet50.h5\")\n","    model.build_pl_model(vggface_model=vggface, before_activ=loss_config[\"PL_before_activ\"])\n","    train_batchA = DataLoader(train_A, train_AnB, batchSize, img_dirA_bm_eyes,\n","                              RESOLUTION, num_cpus, K.get_session(), **da_config)\n","    train_batchB = DataLoader(train_B, train_AnB, batchSize, img_dirB_bm_eyes, \n","                              RESOLUTION, num_cpus, K.get_session(), **da_config)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Ll7g7mGU3jss","colab":{}},"source":["# Start training\n","t0 = time.time()\n","\n","# This try/except is meant to resume training if we disconnected from Colab\n","try:\n","    gen_iterations\n","    print(f\"Resume training from iter {gen_iterations}.\")\n","except:\n","    gen_iterations = 0\n","\n","errGA_sum = errGB_sum = errDA_sum = errDB_sum = 0\n","errGAs = {}\n","errGBs = {}\n","# Dictionaries are ordered in Python 3.6\n","for k in ['ttl', 'adv', 'recon', 'edge', 'pl']:\n","    errGAs[k] = 0\n","    errGBs[k] = 0\n","\n","display_iters = 300\n","global TOTAL_ITERS\n","\n","global train_batchA, train_batchB\n","train_batchA = DataLoader(train_A, train_AnB, batchSize, img_dirA_bm_eyes, \n","                          RESOLUTION, num_cpus, K.get_session(), **da_config)\n","train_batchB = DataLoader(train_B, train_AnB, batchSize, img_dirB_bm_eyes, \n","                          RESOLUTION, num_cpus, K.get_session(), **da_config)\n","\n","while gen_iterations <= TOTAL_ITERS: \n","    \n","    # Loss function automation\n","    if gen_iterations == (TOTAL_ITERS//5 - display_iters//2):\n","        clear_output()\n","        loss_config['use_PL'] = True\n","        loss_config['use_mask_hinge_loss'] = False\n","        loss_config['m_mask'] = 0.0\n","        reset_session(models_dir)\n","        print(\"Building new loss funcitons...\")\n","        show_loss_config(loss_config)\n","        model.build_train_functions(loss_weights=loss_weights, **loss_config)\n","        print(\"Done.\")\n","    elif gen_iterations == (TOTAL_ITERS//5 + TOTAL_ITERS//10 - display_iters//2):\n","        clear_output()\n","        loss_config['use_PL'] = True\n","        loss_config['use_mask_hinge_loss'] = True\n","        loss_config['m_mask'] = 0.5\n","        reset_session(models_dir)\n","        print(\"Building new loss funcitons...\")\n","        show_loss_config(loss_config)\n","        model.build_train_functions(loss_weights=loss_weights, **loss_config)\n","        print(\"Complete.\")\n","    elif gen_iterations == (2*TOTAL_ITERS//5 - display_iters//2):\n","        clear_output()\n","        loss_config['use_PL'] = True\n","        loss_config['use_mask_hinge_loss'] = True\n","        loss_config['m_mask'] = 0.2\n","        reset_session(models_dir)\n","        print(\"Building new loss funcitons...\")\n","        show_loss_config(loss_config)\n","        model.build_train_functions(loss_weights=loss_weights, **loss_config)\n","        print(\"Done.\")\n","    elif gen_iterations == (TOTAL_ITERS//2 - display_iters//2):\n","        clear_output()\n","        loss_config['use_PL'] = True\n","        loss_config['use_mask_hinge_loss'] = True\n","        loss_config['m_mask'] = 0.4\n","        loss_config['lr_factor'] = 0.3\n","        reset_session(models_dir)\n","        print(\"Building new loss funcitons...\")\n","        show_loss_config(loss_config)\n","        model.build_train_functions(loss_weights=loss_weights, **loss_config)\n","        print(\"Done.\")\n","    elif gen_iterations == (2*TOTAL_ITERS//3 - display_iters//2):\n","        clear_output()\n","        model.decoder_A.load_weights(\"models/decoder_B.h5\") # swap decoders\n","        model.decoder_B.load_weights(\"models/decoder_A.h5\") # swap decoders\n","        loss_config['use_PL'] = True\n","        loss_config['use_mask_hinge_loss'] = True\n","        loss_config['m_mask'] = 0.5\n","        loss_config['lr_factor'] = 1\n","        reset_session(models_dir)\n","        print(\"Building new loss funcitons...\")\n","        show_loss_config(loss_config)\n","        model.build_train_functions(loss_weights=loss_weights, **loss_config)\n","        print(\"Done.\")\n","    elif gen_iterations == (8*TOTAL_ITERS//10 - display_iters//2):\n","        clear_output()\n","        loss_config['use_PL'] = True\n","        loss_config['use_mask_hinge_loss'] = True\n","        loss_config['m_mask'] = 0.1\n","        loss_config['lr_factor'] = 0.3\n","        reset_session(models_dir)\n","        print(\"Building new loss funcitons...\")\n","        show_loss_config(loss_config)\n","        model.build_train_functions(loss_weights=loss_weights, **loss_config)\n","        print(\"Done.\")\n","    elif gen_iterations == (9*TOTAL_ITERS//10 - display_iters//2):\n","        clear_output()\n","        loss_config['use_PL'] = True\n","        loss_config['use_mask_hinge_loss'] = False\n","        loss_config['m_mask'] = 0.0\n","        loss_config['lr_factor'] = 0.1\n","        reset_session(models_dir)\n","        print(\"Building new loss funcitons...\")\n","        show_loss_config(loss_config)\n","        model.build_train_functions(loss_weights=loss_weights, **loss_config)\n","        print(\"Done.\")\n","    \n","    if gen_iterations == 5:\n","        print (\"working.\")\n","    \n","    # Train dicriminators for one batch\n","    data_A = train_batchA.get_next_batch()\n","    data_B = train_batchB.get_next_batch()\n","    errDA, errDB = model.train_one_batch_D(data_A=data_A, data_B=data_B)\n","    errDA_sum +=errDA[0]\n","    errDB_sum +=errDB[0]\n","\n","    # Train generators for one batch\n","    data_A = train_batchA.get_next_batch()\n","    data_B = train_batchB.get_next_batch()\n","    errGA, errGB = model.train_one_batch_G(data_A=data_A, data_B=data_B)\n","    errGA_sum += errGA[0]\n","    errGB_sum += errGB[0]\n","    for i, k in enumerate(['ttl', 'adv', 'recon', 'edge', 'pl']):\n","        errGAs[k] += errGA[i]\n","        errGBs[k] += errGB[i]\n","    gen_iterations+=1\n","    \n","    # Visualization\n","    if gen_iterations % display_iters == 0:\n","        clear_output()\n","            \n","        # Display loss information\n","        show_loss_config(loss_config)\n","        print(\"----------\") \n","        print('[iter %d] Loss_DA: %f Loss_DB: %f Loss_GA: %f Loss_GB: %f time: %f'\n","        % (gen_iterations, errDA_sum/display_iters, errDB_sum/display_iters,\n","           errGA_sum/display_iters, errGB_sum/display_iters, time.time()-t0))  \n","        print(\"----------\") \n","        print(\"Generator loss details:\")\n","        print(f'[Adversarial loss]')  \n","        print(f'GA: {errGAs[\"adv\"]/display_iters:.4f} GB: {errGBs[\"adv\"]/display_iters:.4f}')\n","        print(f'[Reconstruction loss]')\n","        print(f'GA: {errGAs[\"recon\"]/display_iters:.4f} GB: {errGBs[\"recon\"]/display_iters:.4f}')\n","        print(f'[Edge loss]')\n","        print(f'GA: {errGAs[\"edge\"]/display_iters:.4f} GB: {errGBs[\"edge\"]/display_iters:.4f}')\n","        if loss_config['use_PL'] == True:\n","            print(f'[Perceptual loss]')\n","            try:\n","                print(f'GA: {errGAs[\"pl\"][0]/display_iters:.4f} GB: {errGBs[\"pl\"][0]/display_iters:.4f}')\n","            except:\n","                print(f'GA: {errGAs[\"pl\"]/display_iters:.4f} GB: {errGBs[\"pl\"]/display_iters:.4f}')\n","        \n","        # Display images\n","        print(\"----------\") \n","        wA, tA, _ = train_batchA.get_next_batch()\n","        wB, tB, _ = train_batchB.get_next_batch()\n","        print(\"Transformed (masked) results:\")\n","        showG(tA, tB, model.path_A, model.path_B, batchSize)   \n","        print(\"Masks:\")\n","        showG_mask(tA, tB, model.path_mask_A, model.path_mask_B, batchSize)  \n","        print(\"Reconstruction results:\")\n","        showG(wA, wB, model.path_bgr_A, model.path_bgr_B, batchSize)           \n","        errGA_sum = errGB_sum = errDA_sum = errDB_sum = 0\n","        for k in ['ttl', 'adv', 'recon', 'edge', 'pl']:\n","            errGAs[k] = 0\n","            errGBs[k] = 0\n","        \n","        # Save models\n","        model.save_weights(path=models_dir)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"kRD_02DL3ju9","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"lSqr_UTX4wRE"},"source":["## The following cells are from [FaceSwap_GAN_v2.2_video_conversion.ipynb](https://github.com/shaoanlu/faceswap-GAN/blob/master/FaceSwap_GAN_v2.2_video_conversion.ipynb)"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"x58lrjkw6iQM"},"source":["## Video conversion"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"EOi2ZsSa4vf4","colab":{}},"source":["from converter.video_converter import VideoConverter"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"GuDMUcLpYI0c","colab_type":"code","colab":{}},"source":["global model, vggface\n","global train_batchA, train_batchB\n","del model\n","del vggface\n","del train_batchA\n","del train_batchB\n","tf.reset_default_graph()\n","K.clear_session()\n","model = FaceswapGANModel(**arch_config)\n","model.load_weights(path=models_dir)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"R4uUub3A4vi7","colab":{}},"source":["fd = MTCNNFaceDetector(sess=K.get_session(), model_path=\"./mtcnn_weights/\")\n","vc = VideoConverter()\n","vc.set_face_detector(fd)\n","vc.set_gan_model(model)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"MxwjrVoc4vmQ","colab":{}},"source":["options = {\n","    # ===== Fixed =====\n","    \"use_smoothed_bbox\": True,\n","    \"use_kalman_filter\": True,\n","    \"use_auto_downscaling\": False,\n","    \"bbox_moving_avg_coef\": 0.65,\n","    \"min_face_area\": 35 * 35,\n","    \"IMAGE_SHAPE\": model.IMAGE_SHAPE,\n","    # ===== Tunable =====\n","    \"kf_noise_coef\": 1e-3,\n","    \"use_color_correction\": \"hist_match\",\n","    \"detec_threshold\": 0.8,\n","    \"roi_coverage\": 0.9,\n","    \"enhance\": 0.,\n","    \"output_type\": 3,\n","    \"direction\": \"AtoB\", # ==================== This line determines the transform direction ====================\n","}"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"qyuELtb94vpr","colab":{}},"source":["if options[\"direction\"] == \"AtoB\":\n","    input_fn = fn_source_video\n","    output_fn = \"OUTPUT_VIDEO_AtoB.mp4\"\n","elif options[\"direction\"] == \"BtoA\":\n","    input_fn = fn_target_video\n","    output_fn = \"OUTPUT_VIDEO_BtoA.mp4\"\n","\n","duration = None # None or a non-negative float tuple: (start_sec, end_sec). Duration of input video to be converted"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Sem7RMzm4vr6","colab":{}},"source":["vc.convert(input_fn=input_fn, output_fn=output_fn, options=options, duration=duration)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"QwKOc5Jt5oFO"},"source":["# Download result video"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"M0MkktlHC5sh","colab":{}},"source":["from google.colab import files"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"hwDUxwlL4voW","colab":{}},"source":["if options[\"direction\"] == \"AtoB\":\n","    files.download(\"OUTPUT_VIDEO_AtoB.mp4\")\n","elif options[\"direction\"] == \"BtoA\":\n","    files.download(\"OUTPUT_VIDEO_BtoA.mp4\")"],"execution_count":0,"outputs":[]}]}